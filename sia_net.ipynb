{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64972929-8c52-497d-bb5c-0a9099bdd368",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-23T10:29:20.519079Z",
     "iopub.status.busy": "2024-12-23T10:29:20.518028Z",
     "iopub.status.idle": "2024-12-23T10:29:20.528118Z",
     "shell.execute_reply": "2024-12-23T10:29:20.526885Z",
     "shell.execute_reply.started": "2024-12-23T10:29:20.519041Z"
    },
    "id": "93861925-12b5-4a51-b439-5e7f3212367b",
    "outputId": "404715bd-6604-483e-ad3d-7c51485c8104",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "import os, sys, tarfile, base64\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from random import randint\n",
    "from math import sqrt\n",
    "#from keras import backend as K\n",
    "from tensorflow.python.ops import gen_nn_ops\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras.metrics import * \n",
    "from tensorflow.keras.regularizers import *\n",
    "from tensorflow.keras.activations import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras import backend as K \n",
    "from tensorflow_addons.optimizers import Lookahead, RectifiedAdam\n",
    "from tensorflow.keras.preprocessing.image import *\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.utils import *\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4474f711-9d4b-4378-b086-b2627aaf5214",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-23T10:29:29.206027Z",
     "iopub.status.busy": "2024-12-23T10:29:29.205658Z",
     "iopub.status.idle": "2024-12-23T10:29:29.773848Z",
     "shell.execute_reply": "2024-12-23T10:29:29.772466Z",
     "shell.execute_reply.started": "2024-12-23T10:29:29.205997Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1664096842315,
     "user": {
      "displayName": "周煜航",
      "userId": "06596322764301497974"
     },
     "user_tz": -480
    },
    "id": "918bb8c2-73bb-4b99-bc31-866808638dbf",
    "outputId": "319e70aa-1feb-48bb-d43b-47f18b75fcb1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "newcollege_images_path = \"./NewCollege\"\n",
    "newcollege = sorted(\n",
    "    [str(newcollege_images_path +\"/\"+ f) for f in os.listdir(newcollege_images_path)]\n",
    ")\n",
    "citycentre_images_path = \"./CityCentre\"\n",
    "\n",
    "citycentre = sorted(\n",
    "    [str(citycentre_images_path +\"/\"+ f) for f in os.listdir(citycentre_images_path)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92711471-0d0c-4bd7-a323-fca50f4fdec4",
   "metadata": {
    "id": "dac19292-7601-4b63-9f61-ab66cf3f5464"
   },
   "outputs": [],
   "source": [
    "newcollege_gt = np.loadtxt(\"./drive/MyDrive/NewCollegeGroundTruth.txt\", delimiter=',')\n",
    "citycentre_gt = np.loadtxt(\"./drive/MyDrive/CityCentreGroundTruth.txt\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a16eee3-c018-4d73-8693-d208eda1f8fb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1664096848009,
     "user": {
      "displayName": "周煜航",
      "userId": "06596322764301497974"
     },
     "user_tz": -480
    },
    "id": "d535da0f-7c8e-4d43-8eb5-9184f855fd07",
    "outputId": "b6ea92f4-8ddb-48be-e507-da19c74bfd80"
   },
   "outputs": [],
   "source": [
    "with open(\"./drive/MyDrive/NewCollegeGPS.txt\", 'r') as f:\n",
    "    newcollege_gps = [line.split()[1:] for line in f]   \n",
    "# Converting to float for further work\n",
    "newcollege_gps = np.array(newcollege_gps, dtype=np.float32)\n",
    "# Deleting all the NaN values from the set - this problem only occurs in New College\n",
    "newcollege_gps = newcollege_gps[:1984]\n",
    "print(f\"New size New College: {len(newcollege_gps)}\")\n",
    "with open(\"./drive/MyDrive/CityCentreGPS.txt\", 'r') as f:\n",
    "    citycentre_gps = [line.split()[1:] for line in f] \n",
    "# Converting to float for further work\n",
    "citycentre_gps = np.array(citycentre_gps, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650afb52-510f-4c6b-aba6-72a098602db9",
   "metadata": {
    "id": "a33f1dc7-a5ff-4a40-b949-2d95fad7fd47"
   },
   "outputs": [],
   "source": [
    "# Focal length:\n",
    "fc = [ 367.481519978327754 , 366.991059667167065 ]\n",
    "# Principal point:\n",
    "cc = [ 328.535778962615268 , 233.779960757465176 ]\n",
    "# Distortion coefficients:\n",
    "kc = [ -0.293510277812333 ,\n",
    "        0.065334967950619 ,\n",
    "       -0.000117308680498 ,\n",
    "        0.000304779905426 ,\n",
    "        0.000000000000000 ]\n",
    "\n",
    "im_width  = 640\n",
    "im_height = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def add_random_mask(image, mask_size=50, mask_count=10):\n",
    "\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    for _ in range(mask_count):\n",
    "        x = random.randint(0, width - mask_size)\n",
    "        y = random.randint(0, height - mask_size)\n",
    " \n",
    "        mask[y:y + mask_size, x:x + mask_size] = 255\n",
    "    \n",
    "    masked_image = image.copy()\n",
    "    masked_image[mask == 255] = [0, 0, 0]  \n",
    "\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f2ccdd-cea4-493f-a2b8-a60974e74377",
   "metadata": {
    "id": "69d7acdb-83da-48de-b559-04a74018ff79"
   },
   "outputs": [],
   "source": [
    "def distanceP(a, b):\n",
    "    return sqrt((a[0]-b[0])**2 + (a[1]-b[1])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8809c0-e4d2-42fa-9f2e-d96b236cf9bf",
   "metadata": {
    "id": "0b53da77-e7d7-4d83-a4ab-dc9781611e4f"
   },
   "outputs": [],
   "source": [
    "def createInputOutput(imageset, gt, gps):\n",
    "\n",
    "    \n",
    "    l = len(imageset)    \n",
    "    data_n1 = []\n",
    "    data_n2 = []\n",
    "    data_p1 = []\n",
    "    data_p2 = []\n",
    "    \n",
    "    DELTA_MAX = 3\n",
    "    \n",
    "    DELTA_MIN = 200\n",
    "   \n",
    "    l = min(l, len(gps))\n",
    "    for st in range(0,2):\n",
    "        for i in range(st,l,2):\n",
    "            for j in range(st,l,2):\n",
    "                if float(gt[i][j]) > 0 and distanceP(gps[i], gps[j]) <= DELTA_MAX:\n",
    "                    data_p1.append(i)\n",
    "                    data_p2.append(j)\n",
    "                    \n",
    "                elif distanceP(gps[i], gps[j]) >= DELTA_MIN:\n",
    "                    data_n1.append(i)\n",
    "                    data_n2.append(j)\n",
    "                            \n",
    "    ridx = np.random.permutation(len(data_n1))\n",
    "    data_n1 = int32(data_n1)[ridx].copy()\n",
    "    data_n2 = int32(data_n2)[ridx].copy()\n",
    "    \n",
    "    print(f'After normalising: Closures {len(data_p1)}, Non-closures {len(data_n1)}') \n",
    "    data1n, data2n, outputn = unison_shuffle_triple(data_n1, data_n2, zeros_like(data_n1))\n",
    "    data1p, data2p, outputp = unison_shuffle_triple(data_p1, data_p2, ones_like(data_p1))\n",
    "    return (data1n, data1p), (data2n, data2p), (outputn, outputp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createInputOutput(imageset, gt, gps, mask_size=50, mask_count=5):\n",
    "    l = len(imageset)    \n",
    "    data_n1 = []\n",
    "    data_n2 = []\n",
    "    data_p1 = []\n",
    "    data_p2 = []\n",
    "    \n",
    "    DELTA_MAX = 3\n",
    "    DELTA_MIN = 200\n",
    "    \n",
    "    l = min(l, len(gps))\n",
    "    for st in range(0, 2):\n",
    "        for i in range(st, l, 2):\n",
    "            for j in range(st, l, 2):\n",
    "                if float(gt[i][j]) > 0 and distanceP(gps[i], gps[j]) <= DELTA_MAX:\n",
    "                    data_p1.append(i)\n",
    "                    data_p2.append(j)\n",
    "                    \n",
    "                elif distanceP(gps[i], gps[j]) >= DELTA_MIN:\n",
    "                    data_n1.append(i)\n",
    "                    data_n2.append(j)\n",
    "    \n",
    "    ridx = np.random.permutation(len(data_n1))\n",
    "    data_n1 = np.int32(data_n1)[ridx].copy()\n",
    "    data_n2 = np.int32(data_n2)[ridx].copy()\n",
    "    \n",
    "    print(f'After normalising: Closures {len(data_p1)}, Non-closures {len(data_n1)}')\n",
    "     \n",
    "    data1n, data2n, outputn = unison_shuffle_triple(data_n1, data_n2, np.zeros_like(data_n1))\n",
    "    data1p, data2p, outputp = unison_shuffle_triple(data_p1, data_p2, np.ones_like(data_p1))\n",
    "    \n",
    "    # Now add random masks to the image data\n",
    "    imageset_n1 = [add_random_mask(imageset[i], mask_size, mask_count) for i in data_n1]\n",
    "    imageset_n2 = [add_random_mask(imageset[i], mask_size, mask_count) for i in data_n2]\n",
    "    imageset_p1 = [add_random_mask(imageset[i], mask_size, mask_count) for i in data_p1]\n",
    "    imageset_p2 = [add_random_mask(imageset[i], mask_size, mask_count) for i in data_p2]\n",
    "    \n",
    "    return (imageset_n1, imageset_n2), (imageset_p1, imageset_p2), (outputn, outputp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5d33d0-0440-42c5-b779-3b89599ef28e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46153,
     "status": "ok",
     "timestamp": 1664096896011,
     "user": {
      "displayName": "周煜航",
      "userId": "06596322764301497974"
     },
     "user_tz": -480
    },
    "id": "387220ec-1fa8-4ddf-bc29-97ca3cf3a125",
    "outputId": "30b9e52e-bc6a-4f67-9b66-cbd86c74008f"
   },
   "outputs": [],
   "source": [
    "inputData1NC, inputData2NC, outputDataNC = createInputOutput(newcollege, newcollege_gt, newcollege_gps)\n",
    "inputData1CC, inputData2CC, outputDataCC = createInputOutput(citycentre, citycentre_gt, citycentre_gps)\n",
    "trainData1 = inputData1CC\n",
    "trainData2 = inputData2CC\n",
    "trainData3 = inputData1CC\n",
    "trainDataOut = outputDataCC\n",
    "valData1 = inputData1NC\n",
    "valData2 = inputData2NC\n",
    "valData3 = inputData1NC\n",
    "valDataOut = outputDataNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CapsLayer(Layer):\n",
    "#     def __init__(self, privateCaps_dim,outputCaps_num,outputCaps_dim,r=3):\n",
    "#         super(CapsLayer, self).__init__()\n",
    "#         self.outputCaps_num = outputCaps_num\n",
    "#         self.outputCaps_dim = outputCaps_dim\n",
    "#         self.privateCaps_dim = privateCaps_dim\n",
    "#         self.r = r\n",
    "#         self.epsilon = 1e-9\n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         self.w_ij = self.add_weight(shape=(1,self.outputCaps_num,int(input_shape[2]),int(input_shape[3]),self.outputCaps_dim),\n",
    "#                                      initializer=tf.keras.initializers.RandomNormal(),\n",
    "#                                      trainable=True,name='w_ij')\n",
    "    \n",
    "#     def call(self, u_i):\n",
    "#         u_i = tf.reshape(u_i,shape=(-1,1,u_i.shape[1]*u_i.shape[2]*u_i.shape[3]//self.privateCaps_dim,self.privateCaps_dim,1))\n",
    "#         b_ij = tf.zeros([self.outputCaps_num,u_i.shape[2]//1,1,1],name='b_ij')\n",
    "#         for _ in range(self.r):\n",
    "#             u_hat = tf.matmul(self.w_ij,u_i,transpose_a=True,name='u_hat')\n",
    "#             #print(u_hat.shape)\n",
    "#             c_ij = tf.nn.softmax(b_ij,axis=1,name='c_ij')\n",
    "#             #print(c_ij.shape)\n",
    "#             s_j = tf.reduce_sum(tf.multiply(c_ij,u_hat),axis=2,keepdims=True,name='s_j')\n",
    "#             #print(s_j.shape)\n",
    "#             v_j = self.squash(s_j)\n",
    "#             #print(v_j.shape)\n",
    "#             update = tf.reduce_mean(tf.matmul(u_hat,v_j,transpose_a=True),axis=0)\n",
    "#             #print(update)\n",
    "#             b_ij += update\n",
    "#             #print(b_ij)\n",
    "        \n",
    "#         return v_j\n",
    "    \n",
    "#     def squash(self,vector):\n",
    "#         '''Squashing function corresponding to Eq. 1\n",
    "#         Args:\n",
    "#             vector: A tensor with shape [batch_size, 1, num_caps, vec_len, 1] or [batch_size, num_caps, vec_len, 1].\n",
    "#         Returns:\n",
    "#             A tensor with the same shape as vector but squashed in 'vec_len' dimension.\n",
    "#         '''\n",
    "#         vec_squared_norm = tf.reduce_sum(tf.square(vector), -2, keepdims=True)\n",
    "#         scalar_factor = vec_squared_norm / (1 + vec_squared_norm) / tf.sqrt(vec_squared_norm + self.epsilon)\n",
    "#         vec_squashed = scalar_factor * vector  # element-wise\n",
    "#         return(vec_squashed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(x, axis=-1):\n",
    "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True) + K.epsilon()\n",
    "    scale = K.sqrt(s_squared_norm) / (0.5 + s_squared_norm)\n",
    "    return scale * x\n",
    "def softmax(x, axis=-1):\n",
    "    ex = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
    "    return ex / K.sum(ex, axis=axis, keepdims=True)\n",
    "def caps_batch_dot(x, y):\n",
    "    x = K.expand_dims(x, 2)\n",
    "    if K.int_shape(x)[3] is not None:\n",
    "        y = K.permute_dimensions(y, (0, 1, 3, 2))\n",
    "    o = tf.matmul(x, y)\n",
    "    return K.squeeze(o, 2)\n",
    "\n",
    "class Capsule(Layer):\n",
    "    def __init__(self,\n",
    "                 num_capsule,\n",
    "                 dim_capsule,\n",
    "                 routings=3,\n",
    "                 share_weights=True,\n",
    "                 activation='squash',\n",
    "                 **kwargs):\n",
    "        super(Capsule, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.share_weights = share_weights\n",
    "        if activation == 'squash':\n",
    "            self.activation = squash\n",
    "        else:\n",
    "            self.activation = activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim_capsule = input_shape[-1]\n",
    "        if self.share_weights:\n",
    "            self.kernel = self.add_weight(\n",
    "                name='capsule_kernel',\n",
    "                shape=(1, input_dim_capsule,\n",
    "                       self.num_capsule * self.dim_capsule),\n",
    "                initializer='glorot_uniform',\n",
    "                trainable=True)\n",
    "        else:\n",
    "            if input_shape[-2] is None:\n",
    "                raise ValueError(\"Input Shape must be defied if weights not shared.\")\n",
    "            input_num_capsule = input_shape[-2]\n",
    "            self.kernel = self.add_weight(\n",
    "                name='capsule_kernel',\n",
    "                shape=(input_num_capsule, input_dim_capsule,\n",
    "                       self.num_capsule * self.dim_capsule),\n",
    "                initializer='glorot_uniform',\n",
    "                trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        if self.share_weights:\n",
    "            hat_inputs = K.conv1d(inputs, self.kernel)\n",
    "        else:\n",
    "            hat_inputs = K.local_conv1d(inputs, self.kernel, [1], [1])\n",
    "\n",
    "        batch_size = K.shape(inputs)[0]\n",
    "        input_num_capsule = K.shape(inputs)[1]\n",
    "        hat_inputs = K.reshape(hat_inputs,\n",
    "                               (batch_size, input_num_capsule,\n",
    "                                self.num_capsule, self.dim_capsule))\n",
    "        hat_inputs = K.permute_dimensions(hat_inputs, (0, 2, 1, 3))\n",
    "\n",
    "        b = K.zeros_like(hat_inputs[:, :, :, 0])\n",
    "\n",
    "        \n",
    "        for i in range(self.routings):\n",
    "            c = softmax(b, 1)\n",
    "            o = self.activation(caps_batch_dot(c, hat_inputs))\n",
    "            if i < self.routings - 1:\n",
    "                b = caps_batch_dot(o, hat_inputs)\n",
    "                if K.backend() == 'theano':\n",
    "                    o = K.sum(o, axis=1)\n",
    "        return o\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.num_capsule, self.dim_capsule)\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'num_capsule': self.num_capsule,\n",
    "            'dim_capsule': self.dim_capsule,\n",
    "            'routings': self.routings\n",
    "        }\n",
    "        base_config = super(Capsule, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as k\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "\n",
    "va = Input((224,224,3))\n",
    "vb = Input((224,224,3))\n",
    "\n",
    "from keras import layers, Input, Model, optimizers\n",
    "import keras.backend as K\n",
    "def ACT():\n",
    "    \"\"\"\n",
    "    Activation function.\n",
    "    \"\"\"\n",
    "    return Activation('relu')\n",
    "# A Siamese branch part \n",
    "vggmodel = Sequential([\n",
    "         Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"),\n",
    "         Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"),\n",
    "         MaxPooling2D(pool_size=(2,2),strides=2,name=\"MP1\"),\n",
    "         Conv2D(filters=128,kernel_size=(3,3),padding=\"same\", activation=\"relu\"),\n",
    "         Conv2D(filters=128,kernel_size=(3,3),padding=\"same\", activation=\"relu\"),\n",
    "         MaxPooling2D(pool_size=(2,2),strides=2,name=\"MP2\"),\n",
    "         Conv2D(filters=256,kernel_size=(3,3),padding=\"same\", activation=\"relu\"),\n",
    "         Conv2D(filters=256,kernel_size=(3,3),padding=\"same\", activation=\"relu\"),\n",
    "         Conv2D(filters=256,kernel_size=(3,3),padding=\"same\", activation=\"relu\"),\n",
    "         MaxPooling2D(pool_size=(2,2),strides=2,name=\"MP3\"),\n",
    "         Conv2D(filters=512,kernel_size=(3,3),padding=\"same\", activation=\"relu\"),\n",
    "         Conv2D(filters=512,kernel_size=(3,3),padding=\"same\", activation=\"relu\"),\n",
    "         Conv2D(filters=512,kernel_size=(3,3),padding=\"same\", activation=\"relu\"),\n",
    "         MaxPooling2D(pool_size=(2,2),strides=2,name=\"MP4\"),\n",
    "         Conv2D(filters=512,kernel_size=(3,3),padding=\"same\", activation=\"relu\"),\n",
    "         Conv2D(filters=512,kernel_size=(3,3),padding=\"same\", activation=\"relu\"),\n",
    "         Conv2D(filters=512,kernel_size=(3,3),padding=\"same\", activation=\"relu\"),\n",
    "         MaxPooling2D(pool_size=(2,2),strides=2,name=\"MP5\"),\n",
    "         Dense(4096),\n",
    "         Dense(4096),\n",
    "         Dense(1000),\n",
    "         BatchNormalization(),\n",
    "         Flatten(),\n",
    "      \n",
    "])\n",
    "encoded_image_1 = vggmodel(va) \n",
    "encoded_image_2 = vggmodel(vb)\n",
    "descriptor = concatenate([encoded_image_1, encoded_image_2])\n",
    "final_layer = Flatten()(descriptor)\n",
    "final_layer = Dense(512,activation=ACT())(final_layer)\n",
    "final_layer = BatchNormalization()(final_layer)\n",
    "final_layer = Dense(128,activation=ACT())(final_layer) \n",
    "final_layer = BatchNormalization()(final_layer)\n",
    "final_layer = Dense(64,activation=ACT())(final_layer)\n",
    "final_layer = BatchNormalization()(final_layer)\n",
    "final_layer = Dense(1, activation='sigmoid')(final_layer)\n",
    "siamese_vgg = Model(inputs=[va,vb], outputs = final_layer)\n",
    "siamese_vgg.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer=Lookahead(RectifiedAdam(learning_rate = 0.01)),\n",
    "    metrics=[\"accuracy\", \n",
    "             tf.keras.metrics.Precision(), \n",
    "             tf.keras.metrics.Recall(), \n",
    "             tf.keras.metrics.AUC(curve=\"PR\")]\n",
    ")\n",
    "\n",
    "siamese_vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = Input((96,96,3))\n",
    "ab = Input((96,96,3))\n",
    "\n",
    "from keras import layers, Input, Model, optimizers\n",
    "import keras.backend as K\n",
    "def ACT():\n",
    "    \"\"\"\n",
    "    Activation function.\n",
    "    \"\"\"\n",
    "    return Activation('relu')\n",
    "# A Siamese branch part \n",
    "alexmodel = Sequential([\n",
    "         Conv2D(filters=96,  kernel_size=11, strides=4, padding=\"same\",name=\"conv1\"),ACT(),\n",
    "         MaxPooling2D(pool_size=(3,3),strides=2,name=\"MP1\"),\n",
    "         Conv2D(filters=256, kernel_size=(5,5),padding='same',strides=1,name=\"conv2\"), ACT(),\n",
    "         MaxPooling2D(pool_size = (3,3),strides=2,name=\"MP2\"),\n",
    "         Conv2D(filters=384, kernel_size=(3,3),padding='same',strides=1,name=\"conv3\"),ACT(),\n",
    "         Conv2D(filters=384, kernel_size=(3,3),padding='same',strides=1,name=\"conv4\"),ACT(),\n",
    "         Conv2D(filters=256, kernel_size=(3,3),padding='same',strides=1,name=\"conv5\"),ACT(),\n",
    "         MaxPooling2D(pool_size = (3,3),strides=2,name=\"MP3\"),\n",
    "         Dense(4096),\n",
    "         Dense(4096),\n",
    "         Dense(100),\n",
    "         Flatten(),\n",
    "      \n",
    "])\n",
    "encoded_image_1 = alexmodel(aa) \n",
    "encoded_image_2 = alexmodel(ab)\n",
    "descriptor = concatenate([encoded_image_1, encoded_image_2])\n",
    "final_layer = Flatten()(descriptor)\n",
    "final_layer = Dense(128,activation=ACT())(final_layer)\n",
    "final_layer = BatchNormalization()(final_layer)\n",
    "final_layer = Dense(1, activation='sigmoid')(final_layer)\n",
    "siamese_alex = Model(inputs=[aa,ab], outputs = final_layer)\n",
    "siamese_alex.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer=Lookahead(RectifiedAdam(learning_rate = 0.004)),\n",
    "    metrics=[\"accuracy\", \n",
    "             tf.keras.metrics.Precision(), \n",
    "             tf.keras.metrics.Recall(), \n",
    "             tf.keras.metrics.AUC(curve=\"PR\")]\n",
    ")\n",
    "\n",
    "siamese_alex.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153f65f5-d015-4c6e-b671-98133afcd2e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 926,
     "status": "ok",
     "timestamp": 1664093826064,
     "user": {
      "displayName": "周煜航",
      "userId": "06596322764301497974"
     },
     "user_tz": -480
    },
    "id": "7f46fe17-fece-4771-ac38-82ad06674287",
    "outputId": "af4b30ce-2d6f-491f-b111-b929b41cbb75"
   },
   "outputs": [],
   "source": [
    "\n",
    "c = Input((96,128,3))\n",
    "a = Input((224,224,3))\n",
    "b = Input((224,224,3))\n",
    "def ACT():\n",
    "    \"\"\"\n",
    "    Activation function.\n",
    "    \"\"\"\n",
    "    return Activation('relu')\n",
    "    \n",
    "def triplet_loss(x, alpha = 0.2):\n",
    "    # Triplet Loss function.\n",
    "    anchor,positive,negative = x\n",
    "    # distance between the anchor and the positive\n",
    "    pos_dist = K.sum(K.square(anchor-positive),axis=1)\n",
    "    # distance between the anchor and the negative\n",
    "    neg_dist = K.sum(K.square(anchor-negative),axis=1)\n",
    "    # compute loss\n",
    "    basic_loss = pos_dist-neg_dist+alpha\n",
    "    loss = K.maximum(basic_loss,0.0)\n",
    "    return loss\n",
    "# A Siamese branch part \n",
    "model = Sequential([\n",
    "      Conv2D(filters=96,  kernel_size=11, strides=4), BatchNormalization(), ACT(),\n",
    "      MaxPool2D(pool_size=(3,3),strides=2),\n",
    "      Conv2D(filters=256, kernel_size=(5,5),padding='same',strides=1), ACT(),\n",
    "      MaxPool2D(pool_size = (3,3),strides=2),\n",
    "      Conv2D(filters=384, kernel_size=(3,3),padding='same',strides=1),ACT(),\n",
    "      Conv2D(filters=384, kernel_size=(3,3),padding='same',strides=1),ACT(),\n",
    "      Conv2D(filters=256, kernel_size=(3,3),padding='valid',strides=1),ACT(),\n",
    "      MaxPool2D(pool_size = (3,3),strides=2),\n",
    "      Flatten(),\n",
    "])\n",
    "# model_vgg = Sequential([\n",
    "#     Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "#     Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "#     MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "#     Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "#     Conv2D(128, (3, 3), activation='relu', padding='same',),\n",
    "#     MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "#     Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
    "#     Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
    "#     Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
    "#     MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "#     Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
    "#     Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
    "#     Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
    "#     MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "#     Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
    "#     Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
    "#     Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
    "#     MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "#     Flatten(),\n",
    "#     # Dense(4096, activation='relu'),\n",
    "#     # Dense(4096, activation='relu'),\n",
    "#     # Dense(1000, activation='softmax')\n",
    "# ])\n",
    "# ————————————————\n",
    "encoded_image_1 = model(a) \n",
    "encoded_image_2 = model(b)\n",
    "#encoded_image_3 = model(c)\n",
    "# vgg_image_1 = model_vgg(va) \n",
    "# vgg_image_2 = model_vgg(vb)\n",
    "\n",
    "# Concatenate the resulting low-dimensional descriptors into one\n",
    "#descriptor = ([encoded_image_1, encoded_image_2,encoded_image_3])\n",
    "descriptor = concatenate([encoded_image_1, encoded_image_2])\n",
    "#descriptor_vgg = ==([vgg_image_1, vgg_image_2])\n",
    "# The dense \"decision\" layers\n",
    "final_layer = Flatten()(descriptor)\n",
    "final_layer = Dense(4096,activation=ACT())(final_layer)\n",
    "final_layer = BatchNormalization()(final_layer)\n",
    "final_layer = Dropout(0.5)(final_layer)\n",
    "final_layer = Dense(4096,activation=ACT())(final_layer) \n",
    "final_layer = BatchNormalization()(final_layer)\n",
    "final_layer = Dropout(0.5)(final_layer)\n",
    "final_layer = Dense(1024,activation=ACT())(final_layer) \n",
    "final_layer = BatchNormalization()(final_layer)\n",
    "final_layer = Dense(128,activation=ACT())(final_layer)\n",
    "final_layer = BatchNormalization()(final_layer)\n",
    "final_layer = Dense(1, activation='softmax')(final_layer)\n",
    "\n",
    "\n",
    "#---------vgg \n",
    "# final_layer_vgg=Flatten()(descriptor_vgg)\n",
    "# final_layer_vgg=Dense(4096,activation=ACT())(final_layer_vgg)\n",
    "# final_layer_vgg=BatchNormalization()(final_layer_vgg)\n",
    "# final_layer_vgg=Dense(4096,activation=ACT())(final_layer_vgg)\n",
    "# final_layer_vgg=BatchNormalization()(final_layer_vgg)\n",
    "# final_layer_vgg=Dense(1000,activation='sigmoid')(final_layer_vgg)\n",
    "# final_layer_vgg=BatchNormalization()(final_layer_vgg)\n",
    "# final_layer_vgg = Dense(1, activation='softmax')(final_layer)\n",
    "# Assemble the entire neural network together\n",
    "#siamese_autoencoder = Model(inputs=[a,b,c], outputs = final_layer)\n",
    "siamese_autoencoder = Model(inputs=[a,b], outputs = final_layer)\n",
    "#siamese_autoencoder_vgg=Model(input=[va,vb],outputs = final_layer_vgg)\n",
    "# Make the Siamese branches trainable (change both True to False otherwise)\n",
    "for i in range(len(model.layers)-1):\n",
    "    model.layers[i].trainable = True\n",
    "model.trainable = True\n",
    "\n",
    "# for i in range(len(model_vgg.layers)-1):\n",
    "#     model_vgg.layers[i].trainable = True\n",
    "# model_vgg.trainable = True\n",
    "# Compile the final model\n",
    "siamese_autoencoder.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    #loss=Lambda(triplet_loss)([encoded_image_1, encoded_image_2,encoded_image_3]) \n",
    "    optimizer=Lookahead(RectifiedAdam(lr = 0.01)),\n",
    "    metrics=[\"accuracy\", \n",
    "             tf.keras.metrics.Precision(), \n",
    "             tf.keras.metrics.Recall(), \n",
    "             tf.keras.metrics.AUC(curve=\"PR\")]\n",
    ")\n",
    "\n",
    "# Print the summary of the main model and the Siamese branches\n",
    "siamese_autoencoder.summary()\n",
    "model.summary()\n",
    "# siamese_autoencoder_vgg.summary()\n",
    "# model_vgg.summary()\n",
    "  \n",
    "# Set the coefficients for the branches to the pre-trained ones\n",
    "# for i in range(len(model.layers)-1):\n",
    "#     model.layers[i].set_weights(aemodel.layers[i].get_weights())\n",
    "\n",
    "\n",
    "# import psutil\n",
    "# import humanize\n",
    "# import os\n",
    "# #!pip install gputil\n",
    "# import GPUtil as GPU\n",
    "\n",
    "# GPUs = GPU.getGPUs()\n",
    "# # XXX: only one GPU on Colab and isn’t guaranteed\n",
    "# gpu = GPUs[0]\n",
    "# def printm():\n",
    "#     process = psutil.Process(os.getpid())\n",
    "#     print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n",
    "#     print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "# printm()\n",
    "# !ps -aux|grep python\n",
    "# !kill -9 70\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Input(shape=(96, 96, 3))\n",
    "x = Conv2D(64, (3, 3))(input_image)\n",
    "x=layers.Activation('relu')(x)\n",
    "x=BatchNormalization()(x)\n",
    "x = Conv2D(64, (3, 3))(x)\n",
    "x=layers.Activation('relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3))(x)\n",
    "x=layers.Activation('relu')(x)\n",
    "x = Conv2D(128, (3, 3))(x)\n",
    "x=layers.Activation('relu')(x)\n",
    "x = Reshape((-1, 128))(x)\n",
    "x = Capsule(32, 8, 3, True)(x)  \n",
    "#x = Capsule(32, 8, 3, True)(x)   \n",
    "capsule = Capsule(8, 16, 3, True)(x)\n",
    "output = Lambda(lambda z: K.sqrt(K.sum(K.square(z), 2)))(capsule)\n",
    "# output- Dense(96)(output)\n",
    "capsnet = Model(inputs=[input_image], outputs=[output])\n",
    "#..............................................................................................\n",
    "\n",
    "#.............................................................................................\n",
    "# capsnet=CapsNet()\n",
    "caps1=capsnet(c)\n",
    "caps2=capsnet(b)\n",
    "#descriptor = concatenate([caps1,caps2])\n",
    "L1_layer = Lambda(lambda tensors: K.abs(tensors[0] - tensors[1]))\n",
    "L1_distance = L1_layer([caps1, caps2])\n",
    "final_layer = BatchNormalization()(L1_distance)\n",
    "final_layer = Dense(1, activation='sigmoid')(final_layer)\n",
    "emb_dimentions=96\n",
    "# Assemble the entire neural network together\n",
    "siamese_cap = Model(inputs=[c,b], outputs = final_layer)\n",
    "\n",
    "# Make the Siamese branches trainable (change both True to False otherwise)\n",
    "for i in range(len(capsnet.layers)-1):\n",
    "    capsnet.layers[i].trainable = True\n",
    "capsnet.trainable = True\n",
    "\n",
    "# Compile the final model\n",
    "siamese_cap.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    #loss = triplet_loss(alpha=0.4,emb_dimentions=emb_dimentions),\n",
    "#     optimizer=Adam(learning_rate = 0.00006),\n",
    "   optimizer=Lookahead(RectifiedAdam(learning_rate = 0.004)),\n",
    "    metrics=[\"accuracy\", \n",
    "             tf.keras.metrics.Precision(), \n",
    "             tf.keras.metrics.Recall(), \n",
    "             tf.keras.metrics.AUC(curve=\"PR\")]\n",
    "#     metrics=METRICS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37834719-8b3e-4526-adbd-bf6ef7177a48",
   "metadata": {
    "id": "88c6c991-606b-4955-8db7-a6e6dcdb3787"
   },
   "outputs": [],
   "source": [
    "class DataSequence(tf.keras.utils.Sequence):\n",
    "    def __init__(self, imageset, data1, data2,output, batch_size=256, aug=True):\n",
    "        super().__init__()\n",
    "        self.data1 = data1\n",
    "        self.data2 = data2\n",
    "        #self.data3 = data3\n",
    "        self.output = output\n",
    "        self.batch_size = batch_size\n",
    "        self.internalCounter = 0\n",
    "        self.imageset = imageset\n",
    "        self.aug = aug\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.data1) / self.batch_size)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.batch_size\n",
    "        insA = [ ]\n",
    "        insB = [ ]\n",
    "        #insC = [ ]\n",
    "        outs = [ ]\n",
    "        maxel = self.batch_size\n",
    "        for i in range(maxel):\n",
    "            q = randint(0,1)\n",
    "            ridx = randint(0, len(self.data1[q])-1)\n",
    "            if self.aug and q==1 and rand()<0.1: # every Nth image is the same\n",
    "                q = 0\n",
    "                ridx = randint(0, len(self.data1[q])-1)\n",
    "                insA.append(augment(preprocess_image(self.imageset[self.data1[q][ridx]])))\n",
    "                insB.append(augment(preprocess_image(self.imageset[self.data1[q][ridx]])))\n",
    "                #insC.append(augment(preprocess_image(self.imageset[self.data1[q][ridx]])))\n",
    "                outs.append(1.0)\n",
    "            else:                \n",
    "                if self.aug:\n",
    "                    insA.append(augment(preprocess_image(self.imageset[self.data1[q][ridx]])))\n",
    "                    insB.append(augment(preprocess_image(self.imageset[self.data2[q][ridx]])))\n",
    "                    #insC.append(augment(preprocess_image(self.imageset[self.data3[q][ridx]])))\n",
    "                else:\n",
    "                    insA.append(preprocess_image(self.imageset[self.data1[q][ridx]]))\n",
    "                    insB.append(preprocess_image(self.imageset[self.data2[q][ridx]]))\n",
    "                    #insC.append(preprocess_image(self.imageset[self.data3[q][ridx]]))\n",
    "                outs.append(self.output[q][ridx])\n",
    "        \n",
    "        return (float32(insA),float32(insB)), float32(outs)\n",
    "\n",
    "x_train = DataSequence(citycentre, trainData1, trainData2, trainDataOut, batch_size=200)    \n",
    "x_val   = DataSequence(newcollege, valData1, valData2, valDataOut,   batch_size=100, aug=False)   \n",
    "\n",
    "\n",
    "# Generator as a function\n",
    "def funcGen(gen):\n",
    "    while(True):\n",
    "        for ex in gen:\n",
    "            yield ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0caf6b1-53c7-4b29-ae23-a104589d17c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "executionInfo": {
     "elapsed": 592164,
     "status": "error",
     "timestamp": 1664094427043,
     "user": {
      "displayName": "周煜航",
      "userId": "06596322764301497974"
     },
     "user_tz": -480
    },
    "id": "aa806c81-bf16-4b95-a46b-5dc5881183ad",
    "outputId": "b759b731-7583-4993-dabe-60b8a2376801"
   },
   "outputs": [],
   "source": [
    "for step in range(100):\n",
    "    history = siamese_autoencoder.fit(\n",
    "        funcGen(x_train),\n",
    "        epochs=100,\n",
    "        #batch_size=16,\n",
    "        steps_per_epoch=100,\n",
    "        validation_data = funcGen(x_val),\n",
    "        validation_steps = 100,\n",
    "        callbacks = [\n",
    "            ReduceLROnPlateau(\n",
    "                monitor=\"val_loss\",\n",
    "                factor=0.2,\n",
    "                patience=5,\n",
    "                verbose=1,\n",
    "            ),\n",
    "            EarlyStopping(\n",
    "                monitor=\"val_loss\",\n",
    "                patience=5,\n",
    "                verbose=1,\n",
    "                restore_best_weights=True,\n",
    "            ),\n",
    "            ModelCheckpoint(\n",
    "                'alex-Loss-cc-nc-g-checkpoint',\n",
    "                monitor=\"val_loss\",\n",
    "                save_best_only=True,\n",
    "                save_weights_only=True,\n",
    "            ),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12554591-a139-4129-9ebf-4a6e38d455b1",
   "metadata": {
    "id": "895c5339-efdc-409a-aa4b-87d4fa22c389"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8976cd7-ab4f-4852-adf6-a075143441e5",
   "metadata": {
    "id": "31dd3e9e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8738ca3c-d256-4964-abb6-d69081a20c07",
   "metadata": {
    "id": "4d4976ef"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2503921,
     "sourceId": 4249322,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2503956,
     "sourceId": 4249375,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2503959,
     "sourceId": 4249379,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2503964,
     "sourceId": 4249385,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2503967,
     "sourceId": 4249389,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2503971,
     "sourceId": 4249394,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3437251,
     "sourceId": 6000803,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30513,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
